
<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Lipschitz singularities in Diffusion Models | Zhantao&#39;Log</title>
<meta name="keywords" content="Lipschitz singularities, diffusion models, image-generation" />
<meta name="description" content="[Updated on 2024-07-19]: Discuss the Lipschitz singularities in diffusion models.">
<meta name="author" content="Zhantao Yang">
<link rel="canonical" href="https://ztyang23.github.io/posts/lipschitz-singularities-in-diffusion-models/" />
<link href="../../assets/css/style.css" rel="preload stylesheet">
<script defer src="../../assets/js/style.js"></script>
<link rel="icon" href="https://ztyang23.github.io/favicon_peach.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://ztyang23.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://ztyang23.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://ztyang23.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://ztyang23.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-HFT45VFBX6"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-HFT45VFBX6', { 'anonymize_ip': false });
}
</script>
<meta property="og:title" content="Lipschitz singularities in Diffusion Models" />
<meta property="og:description" content="[Updated on 2024-07-19]: Discuss the Lipschitz singularities in diffusion models." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://ztyang23.github.io/posts/lipschitz-singularities-in-diffusion-models/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-07-19T00:00:00&#43;00:00" />
<meta property="article:modified_time" content="2024-07-19T00:00:00&#43;00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Lipschitz singularities in Diffusion Models?"/>
<meta name="twitter:description" content="[Updated on 2024-07-19]: Discuss the Lipschitz singularities in diffusion models."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://ztyang23.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Lipschitz singularities in Diffusion Models.",
      "item": "https://ztyang23.github.io/posts/lipschitz-singularities-in-diffusion-models/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Lipschitz singularities in Diffusion Models.",
  "name": "Lipschitz singularities in Diffusion Models.",
  "description": "[Updated on 2024-07-19: inital version of discussion on the Lipschitz singularities in diffusion models.",
  "keywords": [
    "diffusion model", "Lipschitz singularity"
  ],
  "wordCount" : "6626",
  "inLanguage": "en",
  "datePublished": "2024-07-1T00:00:00Z",
  "dateModified": "2024-08-1T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Zhantao Yang"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://ztyang23.github.io/posts/lipschitz-singularities-in-diffusion-models/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Zhantao Yang",
    "logo": {
      "@type": "ImageObject",
      "url": "https://ztyang23.github.io/favicon_peach.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$','$$'], ['\\[', '\\]']],
      processEscapes: true,
      processEnvironments: true
    },
    options: {
      skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
    }
  };

  window.addEventListener('load', (event) => {
      document.querySelectorAll("mjx-container").forEach(function(x){
        x.parentElement.classList += 'has-jax'})
    });

</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>


<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://ztyang23.github.io/" accesskey="h" title="Zhantao&#39;Log (Alt + H)">Zhantao&#39;Log</a>
            <span class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </span>
        </div>
        <ul id="menu">
            <li>
                <a href="https://ztyang23.github.io/" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
            <li>
                <a href="https://ztyang23.github.io/archives" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="https://ztyang23.github.io/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://ztyang23.github.io/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="https://ztyang23.github.io/faq" title="FAQ">
                    <span>FAQ</span>
                </a>
            </li>
            <li>
                <a href="https://www.emojisearch.app/" title="emojisearch.app">
                    <span>emojisearch.app</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title">
      Lipschitz singularities in Diffusion Models.
    </h1>
    <div class="post-meta">Date: July 1, 2024  |  Estimated Reading Time: 30 min  |  Author: Zhantao Yang

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#what-are-diffusion-models" aria-label="What are Diffusion Models?">What is Lipschitz singularities issue in diffusion models?</a><ul>
                        
                </li>
                <li>
                    <a href="#reverse-diffusion-process" aria-label="Reverse diffusion process">Reverse diffusion process</a></li>
                <li>
                    <a href="#parameterization-of-l_t-for-training-loss" aria-label="Parameterization of $L_t$ for Training Loss">Parameterization of $L_t$ for Training Loss</a><ul>
                        
                <li>
                    <a href="#simplification" aria-label="Simplification">Simplification</a></li>
                <li>
                    <a href="#connection-with-noise-conditioned-score-networks-ncsn" aria-label="Connection with noise-conditioned score networks (NCSN)">Connection with noise-conditioned score networks (NCSN)</a></li></ul>
                </li>
                <li>
                    <a href="#parameterization-of-beta_t" aria-label="Parameterization of $\beta_t$">Parameterization of $\beta_t$</a></li>
                <li>
                    <a href="#parameterization-of-reverse-process-variance-boldsymbolsigma_theta" aria-label="Parameterization of reverse process variance $\boldsymbol{\Sigma}_\theta$">Parameterization of reverse process variance $\boldsymbol{\Sigma}_\theta$</a></li></ul>
                </li>
                <li>
                    <a href="#conditioned-generation" aria-label="Conditioned Generation">Conditioned Generation</a><ul>
                        
                <li>
                    <a href="#classifier-guided-diffusion" aria-label="Classifier Guided Diffusion">Classifier Guided Diffusion</a></li>
                <li>
                    <a href="#classifier-free-guidance" aria-label="Classifier-Free Guidance">Classifier-Free Guidance</a></li></ul>
                </li>
                <li>
                    <a href="#speed-up-diffusion-models" aria-label="Speed up Diffusion Models">Speed up Diffusion Models</a><ul>
                        
                <li>
                    <a href="#fewer-sampling-steps--distillation" aria-label="Fewer Sampling Steps &amp;amp; Distillation">Fewer Sampling Steps &amp; Distillation</a></li>
                <li>
                    <a href="#latent-variable-space" aria-label="Latent Variable Space">Latent Variable Space</a></li></ul>
                </li>
                <li>
                    <a href="#scale-up-generation-resolution-and-quality" aria-label="Scale up Generation Resolution and Quality">Scale up Generation Resolution and Quality</a></li>
                <li>
                    <a href="#model-architecture" aria-label="Model Architecture">Model Architecture</a></li>
                <li>
                    <a href="#quick-summary" aria-label="Quick Summary">Quick Summary</a></li>
                <li>
                    <a href="#citation" aria-label="Citation">Citation</a></li>
                <li>
                    <a href="#references" aria-label="References">References</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><!-- Diffusion models are a new type of generative models that are flexible enough to learn any arbitrarily complex data distribution while tractable to analytically evaluate the distribution. It has been shown recently that diffusion models can generate high-quality images and the performance is competitive to SOTA GAN. -->
<p><span class="update">[Updated on 2024-07-19]: Discuss the Lipschitz singularities in diffusion models.</span><br/></p>
<br>
<p>Diffusion models are a significant type of generative model. They start by defining a forward process that incrementally adds noise to the data distribution; then, they learn a reverse process that gradually samples from random noise to obtain the data distribution. In recent years, a series of image or video generation models based on diffusion models have emerged, such as Stable Diffusion XL(<a href="https://arxiv.org/abs/2307.01952">Dustin Podell et al., 2023</a>), Dall-E 3(<a href="https://cdn.openai.com/papers/dall-e-3.pdf">James Betker et al., 2023</a>), Sora(<a href="https://openai.com/index/video-generation-models-as-world-simulators/">OpenAI, 2024</a>), and so on. Although diffusion models have achieved astounding accomplishments, they still face some challenges, one of which is the problem of Lipschitz singularities. This blog will focus on discussing the Lipschitz singularities issue in diffusion models.</p>
<br>
<h2 id="what-is-lipschitz-singularities">What is Lipschitz singularities issue in diffusion models?<a hidden class="anchor" aria-hidden="true" href="#what-is-lipschitz-singularities">#</a></h1>
    <div style="text-align: center;">
        <img src="../../images/lipschitz_singularities.png" style="width: 50%;" class="center" />
        <figcaption>Fig. 1. Lipschitz singularities issue observed in practice.</figcaption>
    </div>
<p>Several diffusion-based generative models have been proposed with similar ideas underneath, including <em>diffusion probabilistic models</em> (<a href="https://arxiv.org/abs/1503.03585">Sohl-Dickstein et al., 2015</a>), <em>noise-conditioned score network</em> (<strong>NCSN</strong>; <a href="https://arxiv.org/abs/1907.05600">Yang &amp; Ermon, 2019</a>), and <em>denoising diffusion probabilistic models</em> (<strong>DDPM</strong>; <a href="https://arxiv.org/abs/2006.11239">Ho et al. 2020</a>).</p>
<br>
<h2 id="Why-lipschitz-singularities-happen">Why it happens?<a hidden class="anchor" aria-hidden="true" href="#Why-lipschitz-singularities-happen">#</a></h2>
<p>Given a noise schedule, since $\sigma_t = \sqrt{1 - \alpha_t^2}$, we have $\dfrac{d \sigma_t}{dt} = -\dfrac{\alpha_t}{\sqrt{1-\alpha_t^2}} \dfrac{d\alpha_t}{dt}$. As $t$ gets close to 0, the noise schedule requires $\alpha_t \rightarrow 1$, leading to $d \sigma_t / dt \rightarrow \infty$ as long as $\dfrac{d\alpha_t}{dt}|_{t=0}\neq 0$. The partial derivative of the network can be written as </p>
<div>
$$
\dfrac{\partial \mathbf{\epsilon}_\theta\left(\mathbf{x}, t\right)}{\partial t} = \dfrac{\alpha_t}{\sqrt{1-\alpha_t^2}} \dfrac{d\alpha_t}{dt} \nabla_\mathbf{x} \log q_t\left(\mathbf{x}\right) - \dfrac{\partial \nabla_\mathbf{x} \log q_t\left(\mathbf{x}\right)}{\partial t}\sigma_t.
$$
</div>
<p>Note that $\alpha_t \rightarrow 1$ as $t \rightarrow 0$, thus if $\dfrac{d\alpha_t}{dt}|_{t=0}\neq 0$, and $\nabla_\mathbf{x} \log q_t(\mathbf{x})|_{t=0}\neq \mathbf{0}$, then one of the following two must stand.</p>
<div>
$$
\lim \sup_{t\rightarrow 0+} \left\lVert \dfrac{\partial \mathbf{\epsilon}_\theta\left(\mathbf{x}, t\right)}{\partial t} \right\rVert \rightarrow \infty ; \quad \lim \sup_{t\rightarrow 0+} \left\lVert \dfrac{\partial \nabla_\mathbf{x} \log q_t\left(\mathbf{x}\right)}{\partial t}\sigma_t \right\rVert \rightarrow \infty.
$$
</div>
<p>Note that $\dfrac{d\alpha_t}{dt}|_{t=0}\neq 0$ stands for a wide range of noise schedules, including linear, cosine, and quadratic schedules. Besides, we can safely assume that $q_t(\mathbf{x})$ is a smooth process. Therefore, we may often have $\lim \sup_{t\rightarrow 0+} \big\lVert \dfrac{\partial \mathbf{\epsilon}_\theta(\mathbf{x}, t)}{\partial t} \big\rVert \rightarrow \infty$, indicating the infinite Lipschitz constants around $t=0$.</p>
<h3 id="toy-examples">Simple case illustration<a hidden class="anchor" aria-hidden="true" href="#toy-examples">#</a></h3>
<p>Take a simple case that the distribution of data $p(\mathbf{x}_0) \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$ for instance, the score function for any $t\in [0, T]$ can be written as</p>
$$
\nabla_\mathbf{x} \log q_t\left(\mathbf{x}\right) = \nabla_\mathbf{x} \log \left(\dfrac{1}{\sqrt{2\pi}}\exp \left(-\dfrac{\Vert \mathbf{x} \Vert_2^2}{2}\right)\right) = - \mathbf{x}.
$$
<p>Due to the relationship $\mathbf{\epsilon}_\theta(\mathbf{x}, t) = - \sigma_t \nabla_\mathbf{x} \log q_t(\mathbf{x})$ and the fact that the deviation $\dfrac{{\rm d} \sigma_t}{{\rm d} t}$ tends toward $\infty$ as $t\rightarrow 0$, we have $\big\lVert \dfrac{\partial \mathbf{\epsilon}_\theta(\mathbf{x}, t)}{\partial t} \big\rVert \rightarrow \infty$.</p>
<br>
<h2 id="potential-solutions">Potential solutions<a hidden class="anchor" aria-hidden="true" href="#potential-solutions">#</a></h2>
<h3 id="e-tsdm">Early Timstep-Shared Diffusion Model (E-TSDM)<a hidden class="anchor" aria-hidden="true" href="#e-tsdm">#</a></h3>
<br>
<h2 id="appendix">Additional proof<a hidden class="anchor" aria-hidden="true" href="#appendix">#</a></h2>
<br>
<h3 id="noise-schedule">$\rm d \alpha_t / \rm d t$ for widely used noise schedules at zero point<a hidden class="anchor" aria-hidden="true" href="#noise-schedule">#</a></h3>
<p>We have already shown that for an arbitrary complex distribution, given a noise schedule, if $\left. \frac{\rm d\alpha_t}{\rm d t} \right\vert_{t=0} \neq 0$, then we often have $\lim \sup_{t\rightarrow 0+} \big\lVert \frac{\partial \mathbf{\epsilon}_\theta(\mathbf{x}, t)}{\partial t} \big\rVert \rightarrow \infty$, indicating the infinite Lipschitz constants around $t=0$. In this section, we prove that $\left. \frac{\rm d\alpha_t}{\rm d t}\right\vert_{t=0} \neq 0$ stands for three mainstream noise schedules including linear schedule, quadratic schedule and cosine schedule.</p>
<h4 id="noise-schedule-linear">$\rm d \alpha_t / \rm d t$ for linear and quadratic schedules at zero point<a hidden class="anchor" aria-hidden="true" href="#noise-schedule-linear">#</a></h4>
<p>Linear and quadratic schedules are first proposed by \citet{ho2020denoising}. Both of them determine $\{\alpha_t\}_{t=1}^T$ by a pre-designed positive sequence $\{\beta_t\}_{t=1}^T$ and the relationship $\alpha_t := \prod_{i=1}^t \sqrt{1 - \beta_i}$. Note that $t\in \{1,2,\cdots, T\}$ is a discrete index, and $\{\alpha_t\}_{t=1}^T$, $\{\beta_t\}_{t=1}^T$ are discrete parameter sequences in DDPM. However, $\alpha_t$ in $\rm d \alpha_t / \rm d t$ refers to the continuous-time parameter determined by the following score SDE~\citep{song2020score}</p>
$$
\rm d \mathbf{x}(\tau) = - \frac{1}{2}\beta(\tau) \mathbf{x}(\tau) \rm d \tau + \sqrt{\beta(\tau)} \rm d \mathbf{w},~\tau \in [0, 1],
$$
<p>where $\mathbf{w}$ is the standard Wiener process, $\beta(\tau)$ is the continuous version of $\{\beta_t\}_{t=1}^T$ with a continuous time variable $\tau \in [0,1]$ for indexing, and the continuous-time $\alpha_t = \exp{(-\frac{1}{2}\int_{0}^t \beta(s) \rm d s)}$. To avoid ambiguity, let $\alpha(\tau),~\tau\in[0,1]$ denote the continuous version of $\{\alpha_t\}_{t=1}^T$. Thus,</p>
$$
\left. \frac{\rm d \alpha(\tau)}{\rm d \tau}\right\vert_{\tau=0} = \left. -\frac{1}{2} \beta(\tau) \exp{(-\frac{1}{2}\int_{0}^\tau \beta(s) \rm d s)} \right\vert_{\tau=0} = -\frac{1}{2} \beta(0).
$$
<p>Once the continuous function $\beta(\tau)$ is determined for a specific noise schedule, we can obtain $\left. \frac{\rm d \alpha(\tau)}{\rm d \tau}\right\vert_{\tau=0}$ immediately by~\cref{eq:alpha-derivative}.</p>
<p>To obtain $\beta(\tau)$, we first give the expression of $\{\beta_t\}_{t=1}^T$ in linear and quadratic schedules~\citep{ho2020denoising}</p>
$$
\begin{align}
    \text{Linear: }&  \beta_t = \frac{\bar{\beta}_{\rm min}}{T} + \left(\frac{\bar{\beta}_{\rm max}}{T} - \frac{\bar{\beta}_{\rm min}}{T}\right) \cdot \frac{t -1}{T - 1}, \label{eq:beta-linear}\\
    \text{Quadratic: }& \beta_t = \left(\sqrt{\frac{\bar{\beta}_{\rm min}}{T}} + \left(\sqrt{\frac{\bar{\beta}_{\rm max}}{T}} - \sqrt{\frac{\bar{\beta}_{\rm min}}{T}}\right) \cdot \frac{t -1}{T - 1}\right)^2,\label{eq:beta-quadratic}
\end{align}
$$
<p>where $\bar{\beta}_{\rm min}$ and $\bar{\beta}_{\rm max}$ are user-defined hyperparameters. Then, we define an auxiliary sequence $\{\bar{\beta}_t=T\beta_t\}_{t=1}^T$. In the limit of $T\rightarrow \infty$, $\{\bar{\beta}_t\}_{t=1}^T$ becomes the function $\beta(\tau)$ indexed by $\tau \in [0, 1]$</p>
$$
\begin{align}
    \text{Linear: }&  \beta(\tau) = \bar{\beta}_{\rm min} + \left(\bar{\beta}_{\rm max} - \bar{\beta}_{\rm min}\right) \cdot \tau, \label{eq:continuous-beta-linear}\\
    \text{Quadratic: }& \beta(\tau) = \left(\sqrt{\bar{\beta}_{\rm min}} + \left(\sqrt{\bar{\beta}_{\rm max}} - \sqrt{\bar{\beta}_{\rm min}} \right) \cdot \tau\right)^2,\label{eq:continuous-beta-quadratic}
\end{align}
$$
<p>Thus, $\beta(0) = \bar{\beta}_{\rm min}$ for both linear and quadratic schedules, which leads to $\left. \frac{\rm d \alpha(\tau)}{\rm d \tau}\right\vert_{\tau=0} = -\frac{1}{2}\bar{\beta}_{\rm min}$. As a common setting, $\bar{\beta}_{\rm min}$ is a positive real number, thus $\left. \frac{\rm d \alpha(\tau)}{\rm d \tau}\right\vert_{\tau=0} < 0$.</p>
<h4 id="noise-schedule-cosine">$\rm d \alpha_t / \rm d t$ for the cosine schedule at zero point<a hidden class="anchor" aria-hidden="true" href="#noise-schedule-cosine">#</a></h4>
<p>The cosine schedule is designed to prevent abrupt changes in noise level near $t=0$ and $t=T$~\citep{nichol2021improved}. Different from linear and quadratic schedules that define $\{\alpha_t\}_{t=1}^T$ by a pre-designed sequence $\{\beta_t\}_{t=1}^T$, the cosine schedule directly defines $\{\alpha_t\}_{t=1}^T$ as</p>
$$
alpha_t = \frac{f(t)}{f(0)},\quad f(t)=\cos{\left(\frac{t/T + s}{1 + s} \cdot \frac{\pi}{2} \right)},\quad t=1,2,\cdots,T,
$$
<p>where $s$ is a small positive offset. The continuous version of $\{\alpha_t\}_{t=1}^T$ can be obtained in the limit of $T\rightarrow \infty$ as</p>
$$
\alpha(\tau) = \cos{\left(\frac{\tau + s}{1 + s} \cdot \frac{\pi}{2} \right)} / \cos{\left(\frac{s}{1 + s} \cdot \frac{\pi}{2} \right)},\quad \tau\in [0,1].
$$
<p>With \cref{eq:alpha-cosine-continuous}, we can easily get $\left. \frac{\rm d \alpha(\tau)}{\rm d \tau}\right\vert_{\tau=0}$</p>
$$
\left. \frac{\rm d \alpha(\tau)}{\rm d \tau}\right\vert_{\tau=0} = -\frac{\pi}{2(1+s)} \tan{\left(\frac{s}{1 + s} \cdot \frac{\pi}{2} \right)},
$$
<p>which leads to $\left. \frac{\rm d \alpha(\tau)}{\rm d \tau}\right\vert_{\tau=0} < 0$ since $s > 0$.</p>
<h3 id="v-prediction">Lipschitz singularies for v-prediction diffusion models<a hidden class="anchor" aria-hidden="true" href="#v-prediction">#</a></h3>
<p>In \cref{sec:analyze} of the main paper, we prove that noise-prediction diffusion models suffer from Lipschitz singularities issue. In this section, we show that the Lipschitz singularities issue is also an important problem for v-prediction diffusion models from both theoretical and empirical perspectives.</p>    
<p>Theoretically, the optimal solution of v-prediction models is</p>
$$
\begin{aligned}
v(\mathbf{x}, t) &= \underset{v_\theta}{\operatorname{argmin}} \mathbb{E} [ \| v_\theta(\mathbf{x_t}, t) - (\alpha_t \mathbf{\epsilon} - \sigma_t \mathbf{x}_0) \|^2_2 | \mathbf{x}_t = \mathbf{x}] \\\\
&= \mathbb{E}[ \alpha_t \mathbf{\epsilon} - \sigma_t \mathbf{x}_0 | \mathbf{x}_t = \mathbf{x}] \\\\
&= \mathbb{E}\left[ \left. \alpha_t \mathbf{\epsilon} - \sigma_t \frac{\mathbf{x}_t - \sigma_t \mathbf{\epsilon}}{\alpha_t} \right| \mathbf{x}_t = \mathbf{x}\right] \\\\
&= -\frac{\sigma_t}{\alpha_t} x + (\alpha_t + \frac{\sigma^2_t}{\alpha_t}) \mathbb{E}[\mathbf{\epsilon} | \mathbf{x}_t = \mathbf{x}] \\\\
&= -\frac{\sigma_t}{\alpha_t} x - \frac{\alpha^2_t + \sigma^2_t}{\alpha_t} \sigma_t \nabla_x \log q_t(\mathbf{x}) \\\\
&= -\frac{\sigma_t}{\alpha_t} (\mathbf{x} + \nabla_\mathbf{x} \log q_t(\mathbf{x})),
\end{aligned}
$$
<p>where $\mathbf{x} + \nabla_\mathbf{x} \log q_t(\mathbf{x})$ is smooth under the assumption of \cref{prop:xt-diff}, and $\frac{\rm d}{\rm d t}\left(\frac{\sigma_t}{\alpha_t}\right) \rightarrow \frac{\rm d \sigma_t}{\rm d t}$ as $t \rightarrow 0$. Thus, with the same derivation of \cref{prop:xt-diff}, we can conclude that $\lim \sup_{t\rightarrow 0^+} \left\|\frac{\partial v(x, t)}{\partial t}\right\|\rightarrow \infty$. The detailed derivation goes as follows:</p>
<p>Firstly, we can obtain the partial derivative of the v-prediction model over $t$ as </p>
$$
\frac{\partial v(\mathbf{x}, t)}{\partial t} = -\frac{\rm d }{\rm d t}(\frac{\sigma_t}{\alpha_t}) (\mathbf{x} + \nabla_\mathbf{x} \log q_t(\mathbf{x})) - \frac{\sigma_t}{\alpha_t} \frac{\rm d }{\rm d t} (\mathbf{x} + \nabla_\mathbf{x} \log q_t(\mathbf{x})).
$$
<p>Note that $\frac{d}{dt}\left(\frac{\sigma_t}{\alpha_t}\right) = \frac{1}{\alpha_t^2} \left( \alpha_t \frac{\rm d \sigma_t}{\rm d t} - \sigma_t \frac{\rm d \alpha_t}{\rm d t}\right) \rightarrow \frac{\rm d \sigma_t}{\rm d t} = -\frac{\alpha_t}{\sqrt{1 - \alpha_t^2}}\frac{\rm d \alpha_t}{\rm d t}$ as $t \rightarrow 0$ under common settings that $\sigma_0=0$, $\alpha_0=1$, and $\left.\frac{\rm d \alpha_t}{\rm d t}\right|_{t = 0}$ is finite, thus if $\left.\frac{\rm d \alpha_t}{\rm d t}\right|_{t = 0} \neq 0$, and $\mathbf{x} + \nabla_\mathbf{x} \log q_t(\mathbf{x}) \neq \mathbf{0}$, then one of the following two must stand</p>
$$
\lim \sup_{t \rightarrow 0^+} \left\Vert \frac{\partial v(\mathbf{x}, t)}{\partial t} \right\Vert \rightarrow \infty;\quad \lim \sup_{t \rightarrow 0^+}  \left\Vert \frac{\sigma_t}{\alpha_t} \frac{\rm d }{\rm d t} (\mathbf{x} + \nabla_\mathbf{x} \log q_t(\mathbf{x})) \right\Vert \rightarrow \infty.
$$
<p>Under the assumption that $q_t(\mathbf{x})$ is a smooth process, we can conclude that $\lim \sup_{t \rightarrow 0^+} \left\Vert \frac{\partial v(\mathbf{x}, t)}{\partial t} \right\Vert \rightarrow \infty$.</p>

<br>
<h1 id="quick-summary">Quick Summary<a hidden class="anchor" aria-hidden="true" href="#quick-summary">#</a></h1>
<ul>
<li>
<p><strong>Pros</strong>: Tractability and flexibility are two conflicting objectives in generative modeling. Tractable models can be analytically evaluated and cheaply fit data (e.g. via a Gaussian or Laplace), but they cannot easily describe the structure in rich datasets. Flexible models can fit arbitrary structures in data, but evaluating, training, or sampling from these models is usually expensive. Diffusion models are both analytically tractable and flexible</p>
</li>
<li>
<p><strong>Cons</strong>: Diffusion models rely on a long Markov chain of diffusion steps to generate samples, so it can be quite expensive in terms of time and compute. New methods have been proposed to make the process much faster, but the sampling is still slower than GAN.</p>
</li>
</ul>
<h1 id="citation">Citation<a hidden class="anchor" aria-hidden="true" href="#citation">#</a></h1>
<p>Cited as:</p>
<blockquote>
<p>Yang, Zhantao. (Jul 2024). Lipschitz singularities in Diffusion Models? Zhantao&rsquo;Log. https://ztyang23.github.io/posts/lipschitz-singularities-in-diffusion-models/.</p>
</blockquote>
<p>Or</p>
<pre tabindex="0"><code>@article{weng2021diffusion,
  title   = &#34;Lipschitz singularities in Diffusion Models?&#34;,
  author  = &#34;Yang, Zhantao&#34;,
  journal = &#34;ztyang23.github.io&#34;,
  year    = &#34;2024&#34;,
  month   = &#34;Jul&#34;,
  url     = &#34;https://ztyang23.github.io/posts/lipschitz-singularities-in-diffusion-models/&#34;
}
</code></pre><h1 id="references">References<a hidden class="anchor" aria-hidden="true" href="#references">#</a></h1>
<p>[1] Jascha Sohl-Dickstein et al. <a href="https://arxiv.org/abs/1503.03585">“Deep Unsupervised Learning using Nonequilibrium Thermodynamics.”</a> ICML 2015.</p>
<p>[2] Max Welling &amp; Yee Whye Teh. <a href="https://www.stats.ox.ac.uk/~teh/research/compstats/WelTeh2011a.pdf">“Bayesian learning via stochastic gradient langevin dynamics.”</a> ICML 2011.</p>
<p>[3] Yang Song &amp; Stefano Ermon. <a href="https://arxiv.org/abs/1907.05600">“Generative modeling by estimating gradients of the data distribution.”</a> NeurIPS 2019.</p>
<p>[4] Yang Song &amp; Stefano Ermon. <a href="https://arxiv.org/abs/2006.09011">“Improved techniques for training score-based generative models.”</a>  NeuriPS 2020.</p>
<p>[5] Jonathan Ho et al. <a href="https://arxiv.org/abs/2006.11239">“Denoising diffusion probabilistic models.”</a> arxiv Preprint arxiv:2006.11239 (2020). [<a href="https://github.com/hojonathanho/diffusion">code</a>]</p>
<p>[6] Jiaming Song et al. <a href="https://arxiv.org/abs/2010.02502">“Denoising diffusion implicit models.”</a> arxiv Preprint arxiv:2010.02502 (2020). [<a href="https://github.com/ermongroup/ddim">code</a>]</p>
<p>[7] Alex Nichol &amp; Prafulla Dhariwal. <a href="https://arxiv.org/abs/2102.09672">“Improved denoising diffusion probabilistic models”</a> arxiv Preprint arxiv:2102.09672 (2021). [<a href="https://github.com/openai/improved-diffusion">code</a>]</p>
<p>[8] Prafula Dhariwal &amp; Alex Nichol. <a href="https://arxiv.org/abs/2105.05233">&ldquo;Diffusion Models Beat GANs on Image Synthesis.&rdquo;</a> arxiv Preprint arxiv:2105.05233 (2021). [<a href="https://github.com/openai/guided-diffusion">code</a>]</p>
<p>[9] Jonathan Ho &amp; Tim Salimans. <a href="https://arxiv.org/abs/2207.12598">&ldquo;Classifier-Free Diffusion Guidance.&rdquo;</a> NeurIPS 2021 Workshop on Deep Generative Models and Downstream Applications.</p>
<p>[10] Yang Song, et al. <a href="https://openreview.net/forum?id=PxTIG12RRHS">&ldquo;Score-Based Generative Modeling through Stochastic Differential Equations.&rdquo;</a> ICLR 2021.</p>
<p>[11] Alex Nichol, Prafulla Dhariwal &amp; Aditya Ramesh, et al. <a href="https://arxiv.org/abs/2112.10741">&ldquo;GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models.&rdquo;</a> ICML 2022.</p>
<p>[12] Jonathan Ho, et al. <a href="https://arxiv.org/abs/2106.15282">&ldquo;Cascaded diffusion models for high fidelity image generation.&rdquo;</a> J. Mach. Learn. Res. 23 (2022): 47-1.</p>
<p>[13] Aditya Ramesh et al. <a href="https://arxiv.org/abs/2204.06125">&ldquo;Hierarchical Text-Conditional Image Generation with CLIP Latents.&rdquo;</a> arxiv Preprint arxiv:2204.06125 (2022).</p>
<p>[14] Chitwan Saharia &amp; William Chan, et al. <a href="https://arxiv.org/abs/2205.11487">&ldquo;Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding.&rdquo;</a> arxiv Preprint arxiv:2205.11487 (2022).</p>
<p>[15] Rombach &amp; Blattmann, et al. <a href="https://arxiv.org/abs/2112.10752">&ldquo;High-Resolution Image Synthesis with Latent Diffusion Models.&rdquo;</a> CVPR 2022.<a href="https://github.com/CompVis/latent-diffusion">code</a></p>
<p>[16] Song et al. <a href="https://arxiv.org/abs/2303.01469">&ldquo;Consistency Models&rdquo;</a> arxiv Preprint arxiv:2303.01469 (2023)</p>
<p>[17] Salimans &amp; Ho. <a href="https://arxiv.org/abs/2202.00512">&ldquo;Progressive Distillation for Fast Sampling of Diffusion Models&rdquo;</a> ICLR 2022.</p>
<p>[18] Ronneberger, et al. <a href="https://arxiv.org/abs/1505.04597">&ldquo;U-Net: Convolutional Networks for Biomedical Image Segmentation&rdquo;</a> MICCAI 2015.</p>
<p>[19] Peebles &amp; Xie. <a href="https://arxiv.org/abs/2212.09748">&ldquo;Scalable diffusion models with transformers.&rdquo;</a> ICCV 2023.</p>
<p>[20] Zhang et al. <a href="https://arxiv.org/abs/2302.05543">&ldquo;Adding Conditional Control to Text-to-Image Diffusion Models.&rdquo;</a> arxiv Preprint arxiv:2302.05543 (2023).</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://ztyang23.github.io/tags/generative-model/">generative-model</a></li>
      <li><a href="https://ztyang23.github.io/tags/math-heavy/">math-heavy</a></li>
      <li><a href="https://ztyang23.github.io/tags/image-generation/">image-generation</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="https://ztyang23.github.io/posts/2021-09-25-train-large/">
    <span class="title">« </span>
    <br>
    <span>How to Train Really Large Models on Many GPUs?</span>
  </a>
  <a class="next" href="https://ztyang23.github.io/posts/2021-05-31-contrastive/">
    <span class="title"> »</span>
    <br>
    <span>Contrastive Representation Learning</span>
  </a>
</nav>


<div class="share-buttons">
    <a target="_blank" rel="noopener noreferrer" aria-label="share What are Diffusion Models? on twitter"
        href="https://twitter.com/intent/tweet/?text=What%20are%20Diffusion%20Models%3f&amp;url=https%3a%2f%2fztyang23.github.io%2fposts%2f2024-07-19-diffusion-models%2f&amp;hashtags=generative-model%2cmath-heavy%2cimage-generation">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-253.927,424.544c135.939,0 210.268,-112.643 210.268,-210.268c0,-3.218 0,-6.437 -0.153,-9.502c14.406,-10.421 26.973,-23.448 36.935,-38.314c-13.18,5.824 -27.433,9.809 -42.452,11.648c15.326,-9.196 26.973,-23.602 32.49,-40.92c-14.252,8.429 -30.038,14.56 -46.896,17.931c-13.487,-14.406 -32.644,-23.295 -53.946,-23.295c-40.767,0 -73.87,33.104 -73.87,73.87c0,5.824 0.613,11.494 1.992,16.858c-61.456,-3.065 -115.862,-32.49 -152.337,-77.241c-6.284,10.881 -9.962,23.601 -9.962,37.088c0,25.594 13.027,48.276 32.95,61.456c-12.107,-0.307 -23.448,-3.678 -33.41,-9.196l0,0.92c0,35.862 25.441,65.594 59.311,72.49c-6.13,1.686 -12.72,2.606 -19.464,2.606c-4.751,0 -9.348,-0.46 -13.946,-1.38c9.349,29.426 36.628,50.728 68.965,51.341c-25.287,19.771 -57.164,31.571 -91.8,31.571c-5.977,0 -11.801,-0.306 -17.625,-1.073c32.337,21.15 71.264,33.41 112.95,33.41Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share What are Diffusion Models? on linkedin"
        href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fztyang23.github.io%2fposts%2f2024-07-19-diffusion-models%2f&amp;title=What%20are%20Diffusion%20Models%3f&amp;summary=What%20are%20Diffusion%20Models%3f&amp;source=https%3a%2f%2fztyang23.github.io%2fposts%2f2024-07-19-diffusion-models%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share What are Diffusion Models? on reddit"
        href="https://reddit.com/submit?url=https%3a%2f%2fztyang23.github.io%2fposts%2f2024-07-19-diffusion-models%2f&title=What%20are%20Diffusion%20Models%3f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share What are Diffusion Models? on facebook"
        href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fztyang23.github.io%2fposts%2f2024-07-19-diffusion-models%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share What are Diffusion Models? on whatsapp"
        href="https://api.whatsapp.com/send?text=What%20are%20Diffusion%20Models%3f%20-%20https%3a%2f%2fztyang23.github.io%2fposts%2f2024-07-19-diffusion-models%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share What are Diffusion Models? on telegram"
        href="https://telegram.me/share/url?text=What%20are%20Diffusion%20Models%3f&amp;url=https%3a%2f%2fztyang23.github.io%2fposts%2f2024-07-19-diffusion-models%2f">
        <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28">
            <path
                d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
        </svg>
    </a>
</div>

  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2024 <a href="https://ztyang23.github.io/">Zhantao&#39;Log</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://git.io/hugopapermod" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerText = 'copy';

        function copyingDone() {
            copybutton.innerText = 'copied!';
            setTimeout(() => {
                copybutton.innerText = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>