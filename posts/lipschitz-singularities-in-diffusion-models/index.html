
<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Lipschitz singularities in Diffusion Models | Zhantao&#39;Log</title>
<meta name="keywords" content="Lipschitz singularities, diffusion models, image-generation" />
<meta name="description" content="[Updated on 2024-07-22]: Discuss the Lipschitz singularities in diffusion models.">
<meta name="author" content="Zhantao Yang">
<link rel="canonical" href="https://ztyang23.github.io/posts/lipschitz-singularities-in-diffusion-models/" />
<link href="../../assets/css/style.css" rel="preload stylesheet">
<script defer src="../../assets/js/style.js"></script>
<link rel="icon" href="https://ztyang23.github.io/favicon_peach.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://ztyang23.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://ztyang23.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://ztyang23.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://ztyang23.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>

<!-- 引入 MathJax -->
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

<!-- 自定义定理样式 -->
<style>
    .theorem-box {
        border: 1px solid #000;
        padding: 10px;
        margin: 20px 0;
        background-color: #f9f9f9;
    }
    .theorem-title {
        font-weight: bold;
    }
</style>

<script async src="https://www.googletagmanager.com/gtag/js?id=G-HFT45VFBX6"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-HFT45VFBX6', { 'anonymize_ip': false });
}
</script>

<meta property="og:title" content="Lipschitz singularities in Diffusion Models" />
<meta property="og:description" content="[Updated on 2024-07-22]: Discuss the Lipschitz singularities in diffusion models." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://ztyang23.github.io/posts/lipschitz-singularities-in-diffusion-models/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-07-22T00:00:00&#43;00:00" />
<meta property="article:modified_time" content="2024-07-22T00:00:00&#43;00:00" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Lipschitz singularities in Diffusion Models?"/>
<meta name="twitter:description" content="[Updated on 2024-07-22]: Discuss the Lipschitz singularities in diffusion models."/>

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://ztyang23.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Lipschitz singularities in Diffusion Models.",
      "item": "https://ztyang23.github.io/posts/lipschitz-singularities-in-diffusion-models/"
    }
  ]
}
</script>

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Lipschitz singularities in Diffusion Models.",
  "name": "Lipschitz singularities in Diffusion Models.",
  "description": "[Updated on 2024-07-22: inital version of discussion on the Lipschitz singularities in diffusion models.",
  "keywords": [
    "diffusion model", "Lipschitz singularity"
  ],
  "wordCount" : "6626",
  "inLanguage": "en",
  "datePublished": "2024-07-22T00:00:00Z",
  "dateModified": "2024-08-22T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Zhantao Yang"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://ztyang23.github.io/posts/lipschitz-singularities-in-diffusion-models/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Zhantao Yang",
    "logo": {
      "@type": "ImageObject",
      "url": "https://ztyang23.github.io/favicon_peach.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$','$$'], ['\\[', '\\]']],
      processEscapes: true,
      processEnvironments: true
    },
    options: {
      skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
    }
  };

  window.addEventListener('load', (event) => {
      document.querySelectorAll("mjx-container").forEach(function(x){
        x.parentElement.classList += 'has-jax'})
    });

</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>


<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://ztyang23.github.io/" accesskey="h" title="Zhantao&#39;Log (Alt + H)">Zhantao&#39;Log</a>
            <span class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </span>
        </div>
        <!-- <ul id="menu">
            <li>
                <a href="https://ztyang23.github.io/" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
            <li>
                <a href="https://ztyang23.github.io/archives" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="https://ztyang23.github.io/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://ztyang23.github.io/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="https://ztyang23.github.io/faq" title="FAQ">
                    <span>FAQ</span>
                </a>
            </li>
            <li>
                <a href="https://www.emojisearch.app/" title="emojisearch.app">
                    <span>emojisearch.app</span>
                </a>
            </li>
        </ul> -->
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title">
      Lipschitz singularities in Diffusion Models.
    </h1>
    <div class="post-meta">Date: July 22, 2024  |  Estimated Reading Time: 30 min  |  Author: Zhantao Yang

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#what-is-lipschitz-singularities">1. What is Lipschitz singularities issue in diffusion models?</a><ul>    
                </li>
                <li>
                    <a href="#Why-issue-matters">Why this issue matters?</a></li></ul>

                <li>
                    <a href="#Why-lipschitz-singularities-happen">2. Why it happends?</a><ul>     
                </li>
                <li>
                    <a href="#toy-examples">Simple case illustration</a></li></ul>

                <li>
                    <a href="#potential-solutions">3. Potential solutions</a><ul> 
                </li>
                <li>
                    <a href="#e-tsdm">3.1 Early Timstep-Shared Diffusion Model (E-TSDM)</a></li><ul>
                    <li>
                        <a href="#e-tsdm-method">3.1.1 Method</a></li>
                    <li>
                        <a href="#e-tsdm-analysis">3.1.2 Analysis of estimation error</a></li>
                    <li>
                        <a href="#e-tsdm-results">3.1.3 Results</a></li></ul>
                <li>
                    <a href="#alternative-methods">3.2 Alternative methods</a></li><ul>
                    <li>
                        <a href="#regularization">3.2.1 Regularization</a></li>
                    <li>
                        <a href="#modified-noise-schedule">3.2.2 Modification of noise schedules</a></li></ul></ul>

                <li>
                    <a href="#appendix">4. Additional proof</a><ul> 
                </li>
                <li>
                    <a href="#noise-schedule">4.1 $\rm d \alpha_t / \rm d t$ for widely used noise schedules at zero point</a></li><ul>
                <li>
                    <a href="#noise-schedule-linear">4.1.1 $\rm d \alpha_t / \rm d t$ for linear and quadratic schedules at zero point</a></li>
                <li>
                    <a href="#noise-schedule-cosine">4.1.2 $\rm d \alpha_t / \rm d t$ for the cosine schedule at zero point</a></li></ul>
                <li>
                    <a href="#v-prediction">4.2 Lipschitz singularies for v-prediction diffusion models</a></li>
                <li>
                    <a href="#estimation-error">4.3 Proof of estimation error</a></li></ul>

                <li>
                    <a href="#citation" aria-label="Citation">Citation</a></li>
                <li>
                    <a href="#references" aria-label="References">References</a>

                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><!-- Diffusion models are a new type of generative models that are flexible enough to learn any arbitrarily complex data distribution while tractable to analytically evaluate the distribution. It has been shown recently that diffusion models can generate high-quality images and the performance is competitive to SOTA GAN. -->
<p><span class="update">[Updated on 2024-07-22]: Discuss the Lipschitz singularities in diffusion models.</span><br/></p>
<br>
<p>Diffusion models are a significant type of generative model. They start by defining a forward process that incrementally adds noise to the data distribution; then, they learn a reverse process that gradually samples from random noise to obtain the data distribution. In recent years, a series of image or video generation models based on diffusion models have emerged, such as (<a href="https://arxiv.org/abs/2307.01952">Stable Diffusion XL, Dustin Podell et al., 2023</a>), (<a href="https://cdn.openai.com/papers/dall-e-3.pdf">Dall-E 3, James Betker et al., 2023</a>), (<a href="https://openai.com/index/video-generation-models-as-world-simulators/">Sora, OpenAI, 2024</a>), and so on. Although diffusion models have achieved astounding accomplishments, they still face some challenges, one of which is the problem of Lipschitz singularities. This blog will focus on discussing the Lipschitz singularities issue in diffusion models.</p>
<br>
<h2 id="what-is-lipschitz-singularities">1. What is Lipschitz singularities issue in diffusion models?<a hidden class="anchor" aria-hidden="true" href="#what-is-lipschitz-singularities">#</a></h1>
<div id="fig1">
<figure class="center-figure">
    <img src="../../images/lipschitz_singularities.png" alt="Lipschitz singularities" style="width: 50%;">
    <figcaption>Figure 1. Lipschitz singularities issue observed in practice.</figcaption>
</figure>
</div>
<p>In practice, we surprisingly observe that the <a href="https://arxiv.org/abs/2006.11239">noise-prediction</a> and <a href="https://arxiv.org/abs/2202.00512">v-prediction</a> diffusion models often exhibit a perplexing tendency to possess <b>infinite Lipschitz of network with respect to time variable near the zero point.</b> We call it <b>Lipschitz singularies issue.</b></p>
<h3 id="Why-issue-matters">Why this issue matters?<a hidden class="anchor" aria-hidden="true" href="#Why-issue-matters">#</a></h3>
<p>Since we uniformly sample timesteps for both training and inference processes, large Lipschitz constants <i>w.r.t.</i> time variable pose a significant threat to both training and inference processes of diffusion models. When training, large Lipschitz constants near the zero point affect the training of other parts due to the smooth nature of the network, resulting in instability and inaccuracy. Moreover, since inference requires a smooth network for integration, the large Lipschitz constants probably have a substantial impact on accuracy, particularly for faster samplers. Therefore, the mitigation of Lipschitz singularities holds great potential for enhancing the performance of diffusion models.</p>

<br>
<h2 id="Why-lipschitz-singularities-happen">2. Why it happens?<a hidden class="anchor" aria-hidden="true" href="#Why-lipschitz-singularities-happen">#</a></h2>
<br>
<p>Given a noise schedule, since $\sigma_t = \sqrt{1 - \alpha_t^2}$, we have $\dfrac{d \sigma_t}{dt} = -\dfrac{\alpha_t}{\sqrt{1-\alpha_t^2}} \dfrac{d\alpha_t}{dt}$. As $t$ gets close to 0, the noise schedule requires $\alpha_t \rightarrow 1$, leading to $d \sigma_t / dt \rightarrow \infty$ as long as $\dfrac{d\alpha_t}{dt}|_{t=0}\neq 0$. The partial derivative of the network can be written as </p>
<div id="eq1">
$$
\dfrac{\partial \mathbf{\epsilon}_\theta\left(\mathbf{x}, t\right)}{\partial t} = \dfrac{\alpha_t}{\sqrt{1-\alpha_t^2}} \dfrac{d\alpha_t}{dt} \nabla_\mathbf{x} \log q_t\left(\mathbf{x}\right) - \dfrac{\partial \nabla_\mathbf{x} \log q_t\left(\mathbf{x}\right)}{\partial t}\sigma_t. 
\tag{1}
$$
</div>
<p>Note that $\alpha_t \rightarrow 1$ as $t \rightarrow 0$, thus if $\dfrac{d\alpha_t}{dt}|_{t=0}\neq 0$, and $\nabla_\mathbf{x} \log q_t(\mathbf{x})|_{t=0}\neq \mathbf{0}$, then one of the following two must stand.</p>
<div id="eq2">
$$
\lim \sup_{t\rightarrow 0+} \left\lVert \dfrac{\partial \mathbf{\epsilon}_\theta\left(\mathbf{x}, t\right)}{\partial t} \right\rVert \rightarrow \infty ; \quad \lim \sup_{t\rightarrow 0+} \left\lVert \dfrac{\partial \nabla_\mathbf{x} \log q_t\left(\mathbf{x}\right)}{\partial t}\sigma_t \right\rVert \rightarrow \infty.
\tag{2}
$$
</div>

<p>Note that $\dfrac{d\alpha_t}{dt}|_{t=0}\neq 0$ stands for a wide range of noise schedules, including linear, cosine, and quadratic schedules. Besides, we can safely assume that $q_t(\mathbf{x})$ is a smooth process. Therefore, we may often have $\lim \sup_{t\rightarrow 0+} \big\lVert \dfrac{\partial \mathbf{\epsilon}_\theta(\mathbf{x}, t)}{\partial t} \big\rVert \rightarrow \infty$, indicating the infinite Lipschitz constants around $t=0$.</p>
<h3 id="toy-examples">Simple case illustration<a hidden class="anchor" aria-hidden="true" href="#toy-examples">#</a></h3>
<p>Take a simple case that the distribution of data $p(\mathbf{x}_0) \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$ for instance, the score function for any $t\in [0, T]$ can be written as</p>
<div id="eq3">
$$
\nabla_\mathbf{x} \log q_t\left(\mathbf{x}\right) = \nabla_\mathbf{x} \log \left(\dfrac{1}{\sqrt{2\pi}}\exp \left(-\dfrac{\Vert \mathbf{x} \Vert_2^2}{2}\right)\right) = - \mathbf{x}.
\tag{3}
$$
</div>
<p>Due to the relationship $\mathbf{\epsilon}_\theta(\mathbf{x}, t) = - \sigma_t \nabla_\mathbf{x} \log q_t(\mathbf{x})$ and the fact that the deviation $\dfrac{{\rm d} \sigma_t}{{\rm d} t}$ tends toward $\infty$ as $t\rightarrow 0$, we have $\big\lVert \dfrac{\partial \mathbf{\epsilon}_\theta(\mathbf{x}, t)}{\partial t} \big\rVert \rightarrow \infty$.</p>
<br>
<h2 id="potential-solutions">3. Potential solutions<a hidden class="anchor" aria-hidden="true" href="#potential-solutions">#</a></h2>
<br>
<p>We introduce a potential solution proposed by <a href="https://openreview.net/forum?id=WNkW0cOwiz">Lipschitz singularies in diffusion models, Zhantao, Yang et al., 2024</a>.</p>
<h3 id="e-tsdm">3.1 Early Timstep-Shared Diffusion Model (E-TSDM)<a hidden class="anchor" aria-hidden="true" href="#e-tsdm">#</a></h3>
<h4 id="e-tsdm-method">3.1.1 Method<a hidden class="anchor" aria-hidden="true" href="#e-tsdm-method">#</a></h4>
<p>E-TSDM uniformly divides the target interval near the zero point into $n$ sub-intervals, and uses the same condition values in each sub-interval. The conceptual comparison between E-TSDM and DDPM is shown in <a href="#fig2">Figure 2</a>.</p>
<div id="fig2">
<figure class="center-figure">
    <img src="../../images/e_tsdm.png" style="width: 80%;">
    <figcaption>Figure 2. Conceptual comparison between DDPM and E-TSDM.</figcaption>
</figure>
</div>
<p>Specifically, we consider the interval near the zero point suffering from large Lipschitz constants, denoted as $[0, \tilde{t})$, where $\tilde{t}$ indicates the length of the target interval. E-TSDM uniformly divides this interval into $n$ sub-intervals represented as a sequence $\mathbb{T}=\{t_0, t_1, \cdots, t_n\}$, where $0=t_0 &lt t_1 &lt \dots &lt t_n=\tilde{t}$ and $t_1 - t_0 = t_{i} - t_{i-1}, \forall i = 1,2,\cdots,n$. For each sub-interval, E-TSDM employs a single timestep value (the left endpoint of the sub-interval) as the condition, both during training and inference. Utilizing this strategy, E-TSDM effectively enforces zero Lipschitz constants within each sub-interval, with only the timesteps located near the boundaries of the sub-intervals having a Lipschitz constant greater than zero. As a result, the overall Lipschitz constants of the target interval $t\in [0, \tilde{t})$ are significantly reduced. The corresponding training loss can be written as</p>
<div id="eq4">
$$
\mathcal{L}\left(\mathbf{\epsilon}_\theta\right):= \mathbb{E}_{t \sim \mathcal{U}\left(0,T\right), \mathbf{x}_0\sim q\left(\mathbf{x}_0\right), \mathbf{\epsilon} \sim \mathcal{N}\left(0, \mathbf{I}\right)}\left[ \Vert \mathbf{\epsilon}_\theta\left(\alpha_t\mathbf{x}_0+\sigma_t\mathbf{\epsilon}, f_{\mathbb{T}}\left(t\right)\right)-\mathbf{\epsilon} \Vert _2^2\right],
\tag{4}
$$
</div>
<p>where $f_{\mathbb{T}}(t)=\max_{1\le i \le n}\{t_{i-1}\in\mathbb{T}: t_{i-1} \le t\}$ for $t < \tilde{t}$, while $f_{\mathbb{T}}(t)=t$ for $t \ge \tilde{t}$. The corresponding reverse process can be represented as</p>
<div id="eq5">
$$
p_\theta\left(\mathbf{x}_{t-1}|\mathbf{x}_t\right) = \mathcal{N}\left(\mathbf{x}_{t-1};\frac{\alpha_{t-1}}{\alpha_t} \left(\mathbf{x}_t -\frac{\beta_t}{\sigma_t}\mathbf{\epsilon}_\theta\left(\mathbf{x}_t, f_{\mathbb{T}}\left(t\right)\right)\right), \eta_t^2 \mathbf{I}\right),
\tag{5}
$$
</div>
<h4 id="e-tsdm-analysis">3.1.2 Analysis of estimation error<a hidden class="anchor" aria-hidden="true" href="#e-tsdm-analysis">#</a></h4>
<p>In this section, we show that the estimation error of E-TSDM can be bounded by an infinitesimal, and thus the impact of E-TSDM on the estimation accuracy is insignificant. The detailed proof is shown <a href="#estimation-error">here</a>.</p>

<div class="theorem-box" id="theorem1">
<div class="theorem-title">Theorem 1.</div>
<p>Given the chosen $f_{\mathbb{T}}(t)$,  when $t\in[0, \tilde{t})$, the difference between the optimal $\mathbf{\epsilon}_\theta(\mathbf{x}, f_{\mathbb{T}}(t))$ denoted as $\mathbf{\epsilon}^*(\mathbf{x}, f_{\mathbb{T}}(t))$, and $\mathbf{\epsilon}(\mathbf{x}, t) = - \sigma_t \nabla_\mathbf{x} \log q_t(\mathbf{x})$, can be bounded by</p>
<div id="eq6">
$$
\left\Vert \mathbf{\epsilon}^*\left(\mathbf{x}, f_{\mathbb{T}}\left(t\right)\right) - \mathbf{\epsilon}\left(\mathbf{x}, t\right)\right\Vert \leq \sigma_{\tilde{t}} K\left(\mathbf{x}\right) \Delta t + B\left(\mathbf{x}\right) \Delta \sigma_{\max},
\tag{6}
$$
</div>
<p>where</p>
<div id="eq7">
$$
K\left(\mathbf{x}\right)=\sup_{t\neq \tau} \frac{\Vert \nabla_\mathbf{x} \log q_t\left(\mathbf{x}\right) - \nabla_\mathbf{x} \log q_\tau\left(\mathbf{x}\right)\Vert}{|t - \tau|},
\tag{7}
$$
</div>
<div id="eq8">
$$
B\left(\mathbf{x}\right)=\sup_t \Vert \nabla_\mathbf{x} \log q_t\left(\mathbf{x}\right)\Vert,
\tag{8}
$$
</div>
<p>and $\Delta {\sigma_{\max}} = \max_{1\leq i\leq n}|\sigma_{t_i} - \sigma_{t_{i-1}}|$. Note that $K(\mathbf{x})$ and $B(\mathbf{x})$ are finite and $\lim_{\Delta t \rightarrow 0} \Delta \sigma_{\max} = 0$ for any continuous $\sigma_t$ where $\Delta t := \tilde{t} / n$, thus the difference converges to 0 as $\Delta t \rightarrow 0$. Furthermore, the rate of convergence is at least $\frac{1}{2}$-order with respect to $\Delta t$.</p>
</div>
<p>The $\frac{1}{2}$-order convergence rate is relatively fast in optimization. Given this bound, we think the introduced errors of E-TSDM are controllable.</p>

<h4 id="e-tsdm-results">3.1.3 Results<a hidden class="anchor" aria-hidden="true" href="#e-tsdm-results">#</a></h4>
<p>1$)$ E-TSDM can significantly <b>reduce the Lipschitz constants</b>, where the results are shown in <a href="#fig3">Figure 3</a>.</p>
<div id="fig3">
<figure class="center-figure">
    <img src="../../images/lipschitz_constants.png" style="width: 50%;">
    <figcaption>Figure 3. The Lipschitz constants are significantly reduced by applying E-TSDM.</figcaption>
</figure>
</div>
<p>2$)$ E-TSDM <b>exhibits better stability than the baseline</b>. Specifically, we add a small noise with a growing scale to the $\mathbf{x}_{\tilde{t}}$, where $\tilde{t}$ is set to a default value of 100, and observe the resulting difference in the predicted value of $\mathbf{x}_0$, for both E-TSDM and baseline. Our results, as shown in <a href="#fig4">Figure 4</a>, illustrate that E-TSDM's predictions are less affected by perturbations.</p>
<div id="fig4">
<figure class="center-figure">
    <img src="../../images/stability.png" style="width: 50%;">
    <figcaption>Figure 4. Quantitative comparison of the errors caused by a perturbation on the input between E-TSDM and DDPM. Results show that E-TSDM is more stable.</figcaption>
</figure>
</div>
<p>3$)$ E-TSDM <b>performs much better than the baseline</b> on multiple datasets, where the results are shown in <a href="#fig5">Figure 5</a>.</p>
<div id="fig5">
<figure class="center-figure">
    <img src="../../images/result.png" style="width: 50%;">
    <figcaption>Figure 5. E-TSDM outperforms the baseline on all evaluated datasets.</figcaption>
</figure>
</div>
<p>4$)$ E-TSDM <b>works on both both discrete-time and continuous-time scenarios, with different noise schedules</b>, where the results are shown in <a href="#fig6">Figure 6</a>.</p>
<div id="fig6">
<figure class="center-figure">
    <img src="../../images/generalization.png" style="width: 80%;">
    <figcaption>Figure 6. E-TSDM can be generalized to other noise schedules and is still effective in the context of continuous-time diffusion models.</figcaption>
</figure>
</div>
<p>5$)$ E-TSDM <b>can be combined with fast samplers</b>, where the results are shown in <a href="#fig7">Figure 7</a>.</p>
<div id="fig7">
<figure class="center-figure">
    <img src="../../images/acceleration.png" style="width: 80%;">
    <figcaption>Figure 7. E-TSDM perfroms better when combined with fast samples than the baseline.</figcaption>
</figure>
</div>
<p>6$)$ E-TSDM can be applied on the <b>conditional generation</b>. We investigate its performance in the <b>super-resolution task</b>, where the results are shown in <a href="#fig8">Figure 8</a>. E-TSDM outperforms the baseline on the test set, <b>achieving an improvement in PSNR from 24.64 to 25.61, and mitigating the color bias</b> exhibited by the baseline.</p>
<div id="fig8">
<figure class="center-figure">
    <img src="../../images/conditional_generation.png" style="width: 80%;">
    <figcaption>Figure 8. E-TSDM mitigates the color bias occurring in baseline and improves the PSNR from 24.64 to 25.6.</figcaption>
</figure>
</div>
<h3 id="alternative-methods">3.2 Alternative methods<a hidden class="anchor" aria-hidden="true" href="#alternative-methods">#</a></h3>
<p>In this section, we introduce two methods that appear to be effective but actually have no effect. These methods have also been discussed in <a href="https://openreview.net/forum?id=WNkW0cOwiz">Lipschitz singularies in diffusion models, Zhantao, Yang et al., 2024</a>.</p>
<h4 id="regularization">3.2.1 Regularization<a hidden class="anchor" aria-hidden="true" href="#regularization">#</a></h3>
<p>An alternative potential approach is imposing restrictions on the Lipschitz constants via regularization techniques, called <b>Regularization</b>. It necessitates the computation of $\frac{\partial \mathbf{\epsilon}_\theta(\mathbf{x}, t)}{\partial t}$, consequently <b>diminishing training efficiency</b>.
<p>Although Regularization performs slightly better than baseline, but much worse than E-TSDM, indicating that E-TSDM is a better choice than regularization., where the results are shown in <a href="#fig9">Figure 9</a>
<div id="fig9">
<figure class="center-figure">
    <img src="../../images/regularization_noise_schedule.png" style="width: 90%;">
    <figcaption>Figure 9. Quantitative analysis of alternative methods. (a) <b>Regularization</b>: Experimental results show that <b>Regularization</b> can slightly improve the FID of DDPM baseline but performs worse than E-TSDM (b) <b>Modification of noise schedules (Modified-NS)</b>: We implement Modified-NS on linear, quadratic, and cosine schedules. Experimental results on FFHQ $256\times256$ dataset indicate that the performance of Modified-NS is unstable while E-TSDM achieves better synthesis performance.</figcaption>
</figure>
</div>
<h4 id="modified-noise-schedule">3.2.2 Modification of noise schedules<a hidden class="anchor" aria-hidden="true" href="#modified-noise-schedule">#</a></h4>
<p>another potential method involves the modification of noise schedules. Recall that the issue of Lipschitz singularities only arises when the noise schedule satisfies $\frac{d\alpha_t}{dt}|_{t=0} \neq 0$. Therefore, it becomes feasible to adjust the noise schedule to meet the requirement $\frac{d\alpha_t}{dt}|_{t=0} = 0$, thus mitigating the problem of Lipschitz singularities. Although this modification seems feasible, it results in tiny amounts of noise at the beginning stages of the diffusion process, leading to inaccurate predictions. As shown in <a href="#fig9">Figure 9</a>, the performance of Modified-NS is unstable while E-TSDM achieves better synthesis performance.</p>
<br>
<h2 id="appendix">4. Additional proof<a hidden class="anchor" aria-hidden="true" href="#appendix">#</a></h2>
<h3 id="noise-schedule">4.1 $\rm d \alpha_t / \rm d t$ for widely used noise schedules at zero point<a hidden class="anchor" aria-hidden="true" href="#noise-schedule">#</a></h3>
<p>We have already shown that for an arbitrary complex distribution, given a noise schedule, if $\left. \frac{\rm d\alpha_t}{\rm d t} \right\vert_{t=0} \neq 0$, then we often have $\lim \sup_{t\rightarrow 0+} \big\lVert \frac{\partial \mathbf{\epsilon}_\theta(\mathbf{x}, t)}{\partial t} \big\rVert \rightarrow \infty$, indicating the infinite Lipschitz constants around $t=0$. In this section, we prove that $\left. \frac{\rm d\alpha_t}{\rm d t}\right\vert_{t=0} \neq 0$ stands for three mainstream noise schedules including linear schedule, quadratic schedule and cosine schedule.</p>
<h4 id="noise-schedule-linear">4.1.1 $\rm d \alpha_t / \rm d t$ for linear and quadratic schedules at zero point<a hidden class="anchor" aria-hidden="true" href="#noise-schedule-linear">#</a></h4>
<p>Linear and quadratic schedules are first proposed by <a href="https://arxiv.org/abs/2006.11239">DDPM</a>. Both of them determine $\{\alpha_t\}_{t=1}^T$ by a pre-designed positive sequence $\{\beta_t\}_{t=1}^T$ and the relationship $\alpha_t := \prod_{i=1}^t \sqrt{1 - \beta_i}$. Note that $t\in \{1,2,\cdots, T\}$ is a discrete index, and $\{\alpha_t\}_{t=1}^T$, $\{\beta_t\}_{t=1}^T$ are discrete parameter sequences in DDPM. However, $\alpha_t$ in $\rm d \alpha_t / \rm d t$ refers to the continuous-time parameter determined by the following score SDE (<a href="https://arxiv.org/abs/2011.13456">SDE, Yang Song et al., 2021</a>)</p>
<div id="eq9">
$$
\rm d \mathbf{x}(\tau) = - \frac{1}{2}\beta(\tau) \mathbf{x}(\tau) \rm d \tau + \sqrt{\beta(\tau)} \rm d \mathbf{w},~\tau \in [0, 1],
\tag{9}
$$
</div>
<p>where $\mathbf{w}$ is the standard Wiener process, $\beta(\tau)$ is the continuous version of $\{\beta_t\}_{t=1}^T$ with a continuous time variable $\tau \in [0,1]$ for indexing, and the continuous-time $\alpha_t = \exp{(-\frac{1}{2}\int_{0}^t \beta(s) \rm d s)}$. To avoid ambiguity, let $\alpha(\tau),~\tau\in[0,1]$ denote the continuous version of $\{\alpha_t\}_{t=1}^T$. Thus,</p>
<div id="eq10">
$$
\left. \frac{\rm d \alpha(\tau)}{\rm d \tau}\right\vert_{\tau=0} = \left. -\frac{1}{2} \beta(\tau) \exp{(-\frac{1}{2}\int_{0}^\tau \beta(s) \rm d s)} \right\vert_{\tau=0} = -\frac{1}{2} \beta(0).
\tag{10}
$$
</div>
<p>Once the continuous function $\beta(\tau)$ is determined for a specific noise schedule, we can obtain $\left. \frac{\rm d \alpha(\tau)}{\rm d \tau}\right\vert_{\tau=0}$ immediately by <a href="#eq10">Equation (10)</a>.</p>
<p>To obtain $\beta(\tau)$, we first give the expression of $\{\beta_t\}_{t=1}^T$ in <a href="https://arxiv.org/abs/2006.11239">linear and quadratic schedules</a></p>
<div id="eq11">
$$
\begin{align}
    \text{Linear: }&  \beta_t = \frac{\bar{\beta}_{\rm min}}{T} + \left(\frac{\bar{\beta}_{\rm max}}{T} - \frac{\bar{\beta}_{\rm min}}{T}\right) \cdot \frac{t -1}{T - 1}, \label{eq:beta-linear}\\
    \text{Quadratic: }& \beta_t = \left(\sqrt{\frac{\bar{\beta}_{\rm min}}{T}} + \left(\sqrt{\frac{\bar{\beta}_{\rm max}}{T}} - \sqrt{\frac{\bar{\beta}_{\rm min}}{T}}\right) \cdot \frac{t -1}{T - 1}\right)^2,\label{eq:beta-quadratic}
\end{align}
\tag{11}
$$
</div>
<p>where $\bar{\beta}_{\rm min}$ and $\bar{\beta}_{\rm max}$ are user-defined hyperparameters. Then, we define an auxiliary sequence $\{\bar{\beta}_t=T\beta_t\}_{t=1}^T$. In the limit of $T\rightarrow \infty$, $\{\bar{\beta}_t\}_{t=1}^T$ becomes the function $\beta(\tau)$ indexed by $\tau \in [0, 1]$</p>
<div id="eq12">
$$
\begin{align}
    \text{Linear: }&  \beta(\tau) = \bar{\beta}_{\rm min} + \left(\bar{\beta}_{\rm max} - \bar{\beta}_{\rm min}\right) \cdot \tau, \label{eq:continuous-beta-linear}\\
    \text{Quadratic: }& \beta(\tau) = \left(\sqrt{\bar{\beta}_{\rm min}} + \left(\sqrt{\bar{\beta}_{\rm max}} - \sqrt{\bar{\beta}_{\rm min}} \right) \cdot \tau\right)^2,\label{eq:continuous-beta-quadratic}
\end{align}
\tag{12}
$$
</div>
<p>Thus, $\beta(0) = \bar{\beta}_{\rm min}$ for both linear and quadratic schedules, which leads to $\left. \frac{\rm d \alpha(\tau)}{\rm d \tau}\right\vert_{\tau=0} = -\frac{1}{2}\bar{\beta}_{\rm min}$. As a common setting, $\bar{\beta}_{\rm min}$ is a positive real number, thus $\left. \frac{\rm d \alpha(\tau)}{\rm d \tau}\right\vert_{\tau=0} < 0$.</p>
<h4 id="noise-schedule-cosine">4.1.2 $\rm d \alpha_t / \rm d t$ for the cosine schedule at zero point<a hidden class="anchor" aria-hidden="true" href="#noise-schedule-cosine">#</a></h4>
<p>The cosine schedule is designed to prevent abrupt changes in noise level near $t=0$ and $t=T$ (<a href="https://arxiv.org/abs/2102.09672">Improved DDPM, 2021</a>). Different from linear and quadratic schedules that define $\{\alpha_t\}_{t=1}^T$ by a pre-designed sequence $\{\beta_t\}_{t=1}^T$, the cosine schedule directly defines $\{\alpha_t\}_{t=1}^T$ as</p>
<div id="eq13">
$$
alpha_t = \frac{f(t)}{f(0)},\quad f(t)=\cos{\left(\frac{t/T + s}{1 + s} \cdot \frac{\pi}{2} \right)},\quad t=1,2,\cdots,T,
\tag{13}
$$
</div>
<p>where $s$ is a small positive offset. The continuous version of $\{\alpha_t\}_{t=1}^T$ can be obtained in the limit of $T\rightarrow \infty$ as</p>
<div id="eq14">
$$
\alpha(\tau) = \cos{\left(\frac{\tau + s}{1 + s} \cdot \frac{\pi}{2} \right)} / \cos{\left(\frac{s}{1 + s} \cdot \frac{\pi}{2} \right)},\quad \tau\in [0,1].
\tag{14}
$$
</div>
<p>With <a href="#eq14">Equation (14)</a>, we can easily get $\left. \frac{\rm d \alpha(\tau)}{\rm d \tau}\right\vert_{\tau=0}$</p>
<div id="eq15">
$$
\left. \frac{\rm d \alpha(\tau)}{\rm d \tau}\right\vert_{\tau=0} = -\frac{\pi}{2(1+s)} \tan{\left(\frac{s}{1 + s} \cdot \frac{\pi}{2} \right)},
\tag{15}
$$
</div>
<p>which leads to $\left. \frac{\rm d \alpha(\tau)}{\rm d \tau}\right\vert_{\tau=0} < 0$ since $s > 0$.</p>
<br>
<h3 id="v-prediction">4.2 Lipschitz singularies for v-prediction diffusion models<a hidden class="anchor" aria-hidden="true" href="#v-prediction">#</a></h3>
<p>In <a href="#Why-lipschitz-singularities-happen">Section 2</a>, we prove that noise-prediction diffusion models suffer from Lipschitz singularities issue. In this section, we show that the Lipschitz singularities issue is also an important problem for v-prediction diffusion models from both theoretical and empirical perspectives.</p>    
<p>Theoretically, the optimal solution of v-prediction models is</p>
<div id="eq16">
$$
\begin{aligned}
v(\mathbf{x}, t) &= \underset{v_\theta}{\operatorname{argmin}} \mathbb{E} [ \| v_\theta(\mathbf{x_t}, t) - (\alpha_t \mathbf{\epsilon} - \sigma_t \mathbf{x}_0) \|^2_2 | \mathbf{x}_t = \mathbf{x}] \\\\
&= \mathbb{E}[ \alpha_t \mathbf{\epsilon} - \sigma_t \mathbf{x}_0 | \mathbf{x}_t = \mathbf{x}] \\\\
&= \mathbb{E}\left[ \left. \alpha_t \mathbf{\epsilon} - \sigma_t \frac{\mathbf{x}_t - \sigma_t \mathbf{\epsilon}}{\alpha_t} \right| \mathbf{x}_t = \mathbf{x}\right] \\\\
&= -\frac{\sigma_t}{\alpha_t} x + (\alpha_t + \frac{\sigma^2_t}{\alpha_t}) \mathbb{E}[\mathbf{\epsilon} | \mathbf{x}_t = \mathbf{x}] \\\\
&= -\frac{\sigma_t}{\alpha_t} x - \frac{\alpha^2_t + \sigma^2_t}{\alpha_t} \sigma_t \nabla_x \log q_t(\mathbf{x}) \\\\
&= -\frac{\sigma_t}{\alpha_t} (\mathbf{x} + \nabla_\mathbf{x} \log q_t(\mathbf{x})),
\end{aligned}
\tag{16}
$$
</div>
<p>where $\mathbf{x} + \nabla_\mathbf{x} \log q_t(\mathbf{x})$ is smooth under the assumption of <a href="#Why-lipschitz-singularities-happen">Section 2</a>, and $\frac{\rm d}{\rm d t}\left(\frac{\sigma_t}{\alpha_t}\right) \rightarrow \frac{\rm d \sigma_t}{\rm d t}$ as $t \rightarrow 0$. Thus, with the same derivation of <a href="#Why-lipschitz-singularities-happen">Section 2</a>, we can conclude that $\lim \sup_{t\rightarrow 0^+} \left\|\frac{\partial v(x, t)}{\partial t}\right\|\rightarrow \infty$. The detailed derivation goes as follows:</p>
<p>Firstly, we can obtain the partial derivative of the v-prediction model over $t$ as </p>
<div id="eq17">
$$
\frac{\partial v(\mathbf{x}, t)}{\partial t} = -\frac{\rm d }{\rm d t}(\frac{\sigma_t}{\alpha_t}) (\mathbf{x} + \nabla_\mathbf{x} \log q_t(\mathbf{x})) - \frac{\sigma_t}{\alpha_t} \frac{\rm d }{\rm d t} (\mathbf{x} + \nabla_\mathbf{x} \log q_t(\mathbf{x})).
\tag{17}
$$
</div>
<p>Note that $\frac{d}{dt}\left(\frac{\sigma_t}{\alpha_t}\right) = \frac{1}{\alpha_t^2} \left( \alpha_t \frac{\rm d \sigma_t}{\rm d t} - \sigma_t \frac{\rm d \alpha_t}{\rm d t}\right) \rightarrow \frac{\rm d \sigma_t}{\rm d t} = -\frac{\alpha_t}{\sqrt{1 - \alpha_t^2}}\frac{\rm d \alpha_t}{\rm d t}$ as $t \rightarrow 0$ under common settings that $\sigma_0=0$, $\alpha_0=1$, and $\left.\frac{\rm d \alpha_t}{\rm d t}\right|_{t = 0}$ is finite, thus if $\left.\frac{\rm d \alpha_t}{\rm d t}\right|_{t = 0} \neq 0$, and $\mathbf{x} + \nabla_\mathbf{x} \log q_t(\mathbf{x}) \neq \mathbf{0}$, then one of the following two must stand</p>
<div id="eq18">
$$
\lim \sup_{t \rightarrow 0^+} \left\Vert \frac{\partial v(\mathbf{x}, t)}{\partial t} \right\Vert \rightarrow \infty;\quad \lim \sup_{t \rightarrow 0^+}  \left\Vert \frac{\sigma_t}{\alpha_t} \frac{\rm d }{\rm d t} (\mathbf{x} + \nabla_\mathbf{x} \log q_t(\mathbf{x})) \right\Vert \rightarrow \infty.
\tag{18}
$$
<div>
<p>Under the assumption that $q_t(\mathbf{x})$ is a smooth process, we can conclude that $\lim \sup_{t \rightarrow 0^+} \left\Vert \frac{\partial v(\mathbf{x}, t)}{\partial t} \right\Vert \rightarrow \infty$.</p>
<br>
<h3 id="estimation-error">4.3 Proof of estimation error<a hidden class="anchor" aria-hidden="true" href="#estimation-error">#</a></h3>
<p>Here we will first give the derivation of the upper-bound on $\Vert \mathbf{\epsilon}^*(\mathbf{x}, f_{\mathbb{T}}(t)) - \mathbf{\epsilon}(\mathbf{x}, t)\Vert$ when $t \in [0, \tilde{t})$, where $\mathbf{\epsilon}^*(\mathbf{x}, f_{\mathbb{T}}(t))$ denotes the optimal $\mathbf{\epsilon}_\theta(\mathbf{x}, f_{\mathbb{T}}(t))$, and $\mathbf{\epsilon}(\mathbf{x}, t)=-\sigma_t \nabla_\mathbf{x} \log q_t(\mathbf{x})$. Then, we will discuss the convergence rate of the error bound.</p>
<p>For any $t \in [0, \tilde{t})$, there exists an $i \in \{1, 2, \cdots, n\}$ such that $t \in [t_{i-1}, t_i)$. For simplicity, we use $h(\mathbf{x}, t)$ to denote the score function $\nabla_\mathbf{x} \log q_t(\mathbf{x})$, and use $\mathbb{E}_\tau[\cdot]$ to denote the expectation over $\tau \sim \mathcal{U}(t_{i-1}, t_i)$. Thus, we can obtain
<div id="eq19">
$$
\begin{aligned}
\left\Vert \mathbf{\epsilon}^*(\mathbf{x}, f(t)) - \mathbf{\epsilon}(\mathbf{x}, t)\right\Vert &= \left\Vert \mathbb{E}_\tau[\mathbf{\epsilon}(\mathbf{x}, \tau)] - \mathbf{\epsilon}(\mathbf{x}, t)\right\Vert \\
&=\left\Vert \mathbb{E}_\tau [\sigma_\tau  h(\mathbf{x}, \tau)] - \sigma_t h(\mathbf{x}, t)\right\Vert \\
&=\left\Vert \mathbb{E}_\tau [\sigma_\tau  h(\mathbf{x}, \tau) - \sigma_\tau h(\mathbf{x}, t) + \sigma_\tau h(\mathbf{x}, t) - \sigma_t h(\mathbf{x}, t)]\right\Vert \\
&\leq \left\Vert \mathbb{E}_\tau [\sigma_\tau \left(h(\mathbf{x}, \tau) - h(\mathbf{x}, t)\right)] \right\Vert + \left\Vert \mathbb{E}_\tau [(\sigma_\tau - \sigma_t) h(\mathbf{x}, t)] \right\Vert\\
&\leq \mathbb{E}_\tau [\sigma_\tau \Vert h(\mathbf{x}, \tau) - h(\mathbf{x}, t)\Vert ] + \mathbb{E}_\tau [|\sigma_\tau - \sigma_t|]\Vert h(\mathbf{x}, t) \Vert \\
&\leq \sigma_{t_i} \mathbb{E}_\tau [\Vert h(\mathbf{x}, \tau) - h(\mathbf{x}, t)\Vert ] + (\sigma_{t_i} - \sigma_{t_{i-1}})\Vert h(\mathbf{x}, t) \Vert \\
&\leq \sigma_{t_i} K_i(\mathbf{x}) (t_i - t_{i-1}) + B_i(\mathbf{x}) (\sigma_{t_i} - \sigma_{t_{i-1}}) \\
&\leq \sigma_{\tilde{t}} K(\mathbf{x}) \Delta t + B(\mathbf{x}) \Delta \sigma_{\max},
\end{aligned}
\tag{19}
$$
</div>
<p>where $K_i(\mathbf{x})=\sup_{t,\tau\in[t_{i-1}, t_i),t\neq \tau} \frac{\Vert h(\mathbf{x},t) - h(\mathbf{x},\tau)\Vert}{|t - \tau|}$, $B_i(\mathbf{x})=\sup_{t\in[t_{i-1}, t_i)} \Vert h(\mathbf{x}, t)\Vert$, $K(\mathbf{x})=\sup_{t,\tau\in[0, \tilde{t}),t\neq \tau} \frac{\Vert h(\mathbf{x},t) - h(\mathbf{x},\tau)\Vert}{|t - \tau|}$, $B(\mathbf{x})=\sup_{t\in[0, \tilde{t})} \Vert h(\mathbf{x}, t)\Vert$, and $\Delta \sigma_{\max} = \max_{1\leq i\leq n}|\sigma_{t_i} - \sigma_{t_{i-1}}|$. The first equality holds because</p>
<div id="eq20">
$$
\begin{aligned}
\mathbf{\epsilon}(\mathbf{x},t)&=\mathop{\arg\min}_{\mathbf{\epsilon}_\theta} \mathbb{E}[\Vert \mathbf{\epsilon}_\theta(\mathbf{\mathbf{x}}_\tau, \tau) - \mathbf{\epsilon} \Vert_2^2 | \tau=t, \mathbf{\mathbf{x}}_\tau=\mathbf{x}] \\
&=\mathbb{E}[\mathbf{\epsilon} | \tau=t, \mathbf{\mathbf{x}}_\tau=\mathbf{x}], 
\end{aligned}
\tag{20}
$$
</div>
<p>and our optimal $\mathbf{\epsilon}^*(\mathbf{x}, f(t))$ can be expressed as</p>
<div id="eq21">
$$
\begin{aligned}
\mathbf{\epsilon}^*(\mathbf{x}, f(t)) &= \mathbf{\epsilon}^*(\mathbf{x}, t_{i-1}) \\
&=\mathop{\arg\min}_{\mathbf{\epsilon}_\theta} \mathbb{E}_{\tau \sim \mathcal{U}(t_{i-1}, t_i), \mathbf{\epsilon}} [\Vert \mathbf{\epsilon}_\theta(\mathbf{\mathbf{x}}_\tau, t_{i-1}) - \mathbf{\epsilon} \Vert_2^2 | \mathbf{\mathbf{x}}_\tau=\mathbf{x}] \\
&= \mathbb{E}_{\tau \sim \mathcal{U}(t_{i-1}, t_i), \mathbf{\epsilon}} [\mathbf{\epsilon} | \mathbf{\mathbf{x}}_\tau=\mathbf{x}] \\
&= \mathbb{E}_{\tau \sim \mathcal{U}(t_{i-1}, t_i)} \mathbb{E}_{\mathbf{\epsilon}} [\mathbf{\epsilon} | \tau, \mathbf{\mathbf{x}}_\tau=\mathbf{x}] \\
&=\mathbb{E}_{\tau \sim \mathcal{U}(t_{i-1}, t_i)} [\mathbf{\epsilon}(\mathbf{x},\tau)].
\end{aligned}
\tag{21}
$$
</div>
<p>As for the rate of convergence, it is obvious from \cref{eq:error-bound-derivation} that we only need to determine the convergence rate of $\Delta \sigma_{\max}$. Under common settings, $\sigma_t$ is monotonically decreasing and concave for $t \in [0, T]$, thus
<div id="eq22">
$$
\Delta \sigma_{\max} = \max_{1\leq i\leq n}|\sigma_{t_i} - \sigma_{t_{i-1}}|
= \sigma_{t_1} - \sigma_{t_0}
= \sigma_{\Delta t},
\tag{22}
$$
</div> 
<p>where the last equality holds because $\sigma_{t_0} = \sigma_{0} = 0$, and $t_1 = \tilde{t} / n = \Delta t$ as we uniformly divides $[0, \tilde{t})$ into $n$ sub-intervals. Then, we can verify the convergence rate of $\Delta \sigma_{\max}$ as</p>
<div id="eq23">
$$
\begin{aligned}
\lim_{\Delta t \rightarrow 0} \frac{\Delta \sigma_{\max}}{\sqrt{\Delta t}} &= \lim_{\Delta t \rightarrow 0} \sqrt{\frac{\sigma_{\Delta t}^2}{\Delta t}}\\
&= \left. \sqrt{\frac{\rm d \sigma_t^2}{\rm d t} }\right|_{t = 0} \\
&= \left. \sqrt{\frac{\rm d (1 - \alpha_t^2)}{\rm d t} }\right|_{t = 0} \\
&= \left. \sqrt{-2 \alpha_t  \frac{\rm d \alpha_t}{\rm d t}}\right|_{t = 0} \\
&= \left. \sqrt{-2 \frac{\rm d \alpha_t}{\rm d t}}\right|_{t = 0}, 
\end{aligned}
\tag{23}
$$
</div>    
<p>where $\left.\frac{\rm d \alpha_t}{\rm d t}\right|_{t = 0}$ is finite and $\left.\frac{\rm d \alpha_t}{\rm d t}\right|_{t = 0} \leq 0$. Thus, we can conclude that $\Delta \sigma_{\max}$ is at least $\frac{1}{2}$-order convergence with respect to $\Delta t$, and the error bound $\sigma_{\tilde{t}} K(\mathbf{x}) \Delta t + B(\mathbf{x}) \Delta \sigma_{\max}$ is also at least $\frac{1}{2}$-order convergence. This is a relatively fast convergence speed in optimization, and demonstrates that the introduced errors of E-TSDM are controllable.</p>

<h1 id="citation">Citation<a hidden class="anchor" aria-hidden="true" href="#citation">#</a></h1>
<br>
<p>Cited as:</p>
<blockquote>
<p>Yang, Zhantao. (Jul 2024). Lipschitz singularities in Diffusion Models Zhantao&rsquo;Log. https://ztyang23.github.io/posts/lipschitz-singularities-in-diffusion-models/.</p>
</blockquote>
<p>Or</p>
<pre tabindex="0"><code>@article{weng2021diffusion,
  title   = &#34;Lipschitz singularities in Diffusion Models?&#34;,
  author  = &#34;Yang, Zhantao&#34;,
  journal = &#34;ztyang23.github.io&#34;,
  year    = &#34;2024&#34;,
  month   = &#34;Jul&#34;,
  url     = &#34;https://ztyang23.github.io/posts/lipschitz-singularities-in-diffusion-models/&#34;
}
</code></pre><h1 id="references">References<a hidden class="anchor" aria-hidden="true" href="#references">#</a></h1>
<p>[1] Jonathan Ho et al. <a href="https://arxiv.org/abs/2006.11239">"Denoising diffusion probabilistic models."</a> NeuriPS 2020</p>
<p>[2] Dustin Podell et al. <a href="https://arxiv.org/abs/2307.01952">"SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis."</a> ICLR 2024</p>
<p>[3] James Betker et al. <a href="https://cdn.openai.com/papers/dall-e-3.pdf">"Improving Image Generation with Better Captions."</a> 2023</p>
<p>[4] OpenAI. <a href="https://openai.com/index/video-generation-models-as-world-simulators/">"Sora."</a> 2024</p>
<p>[5] Tim Salimans et al. <a href="https://arxiv.org/abs/2202.00512">"Progressive Distillation for Fast Sampling of Diffusion Models."</a> ICLR 2022</p>
<p>[6] Yang Song, et al. <a href="https://arxiv.org/abs/2011.13456">"Score-Based Generative Modeling through Stochastic Differential Equations."</a> ICLR 2021</p>
<p>[7] Alex Nichol, et al. <a href="https://arxiv.org/abs/2102.09672">"Improved Denoising Diffusion Probabilistic Models."</a> ICML 2021</p>
<p>[8] Zhantao Yang, et al. <a href="https://openreview.net/forum?id=WNkW0cOwiz">"Lipschitz singularies in diffusion models."</a> ICLR 2024</p>
</div>


<div class="share-buttons">
    <a target="_blank" rel="noopener noreferrer" aria-label="share Lipschitz singularies in diffusion models on twitter"
        href="https://twitter.com/intent/tweet/?text=What%20are%20Diffusion%20Models%3f&amp;url=https%3a%2f%2fztyang23.github.io%2fposts%2f2024-07-22-diffusion-models%2f&amp;hashtags=generative-model%2cmath-heavy%2cimage-generation">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-253.927,424.544c135.939,0 210.268,-112.643 210.268,-210.268c0,-3.218 0,-6.437 -0.153,-9.502c14.406,-10.421 26.973,-23.448 36.935,-38.314c-13.18,5.824 -27.433,9.809 -42.452,11.648c15.326,-9.196 26.973,-23.602 32.49,-40.92c-14.252,8.429 -30.038,14.56 -46.896,17.931c-13.487,-14.406 -32.644,-23.295 -53.946,-23.295c-40.767,0 -73.87,33.104 -73.87,73.87c0,5.824 0.613,11.494 1.992,16.858c-61.456,-3.065 -115.862,-32.49 -152.337,-77.241c-6.284,10.881 -9.962,23.601 -9.962,37.088c0,25.594 13.027,48.276 32.95,61.456c-12.107,-0.307 -23.448,-3.678 -33.41,-9.196l0,0.92c0,35.862 25.441,65.594 59.311,72.49c-6.13,1.686 -12.72,2.606 -19.464,2.606c-4.751,0 -9.348,-0.46 -13.946,-1.38c9.349,29.426 36.628,50.728 68.965,51.341c-25.287,19.771 -57.164,31.571 -91.8,31.571c-5.977,0 -11.801,-0.306 -17.625,-1.073c32.337,21.15 71.264,33.41 112.95,33.41Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Lipschitz singularies in diffusion models on linkedin"
        href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fztyang23.github.io%2fposts%2f2024-07-22-diffusion-models%2f&amp;title=Lipschitz%20Singularities%20in%20Diffusion%20Models%3f&amp;summary=What%20are%20Diffusion%20Models%3f&amp;source=https%3a%2f%2fztyang23.github.io%2fposts%2f2024-07-22-diffusion-models%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Lipschitz singularies in diffusion models on reddit"
        href="https://reddit.com/submit?url=https%3a%2f%2fztyang23.github.io%2fposts%2f2024-07-22-diffusion-models%2f&title=Lipschitz%20Singularities%20in%20Diffusion%20Models%3f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Lipschitz singularies in diffusion models on facebook"
        href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fztyang23.github.io%2fposts%2f2024-07-22-diffusion-models%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Lipschitz singularies in diffusion models on whatsapp"
        href="https://api.whatsapp.com/send?text=Lipschitz%20Singularities%20in%20Diffusion%20Models%3f%20-%20https%3a%2f%2fztyang23.github.io%2fposts%2f2024-07-22-diffusion-models%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Lipschitz singularies in diffusion models on telegram"
        href="https://telegram.me/share/url?text=Lipschitz%20Singularities%20in%20Diffusion%20Models%3f&amp;url=https%3a%2f%2fztyang23.github.io%2fposts%2f2024-07-22-diffusion-models%2f">
        <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28">
            <path
                d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
        </svg>
    </a>
</div>

  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2024 <a href="https://ztyang23.github.io/">Zhantao&#39;Log</a></span>
    <!-- <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://git.io/hugopapermod" rel="noopener" target="_blank">PaperMod</a>
    </span> -->
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerText = 'copy';

        function copyingDone() {
            copybutton.innerText = 'copied!';
            setTimeout(() => {
                copybutton.innerText = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>